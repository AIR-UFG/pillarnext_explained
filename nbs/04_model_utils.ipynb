{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model: utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp models/model_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import torch.nn as nn\n",
    "import spconv\n",
    "import spconv.pytorch\n",
    "from spconv.core import ConvAlgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|eval: false\n",
    "#|hide\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class Conv(nn.Module):\n",
    "    \"\"\"\n",
    "    A convolutional layer module for neural networks.\n",
    "\n",
    "    This class is a wrapper around the specified convolutional layer type, \n",
    "    providing a convenient way to include convolutional layers in neural networks \n",
    "    with customizable parameters such as input channels, output channels, kernel size, \n",
    "    stride, and padding.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 inplanes:int, # The number of input channels.\n",
    "                 planes:int, # The number of output channels.\n",
    "                 kernel_size:int, # The size of the convolving kernel.\n",
    "                 stride:int, # The stride of the convolution.\n",
    "                 conv_layer:nn.Module=nn.Conv2d, # The convolutional layer class to be used.\n",
    "                 bias:bool=False, # If `True`, adds a learnable bias to the output.\n",
    "                 **kwargs # Arbitrary keyword arguments. Currently supports 'padding'.\n",
    "                 ):\n",
    "        super(Conv, self).__init__()\n",
    "        padding = kwargs.get('padding', kernel_size // 2)  # dafault same size\n",
    "\n",
    "        self.conv = conv_layer(inplanes, planes, kernel_size=kernel_size, stride=stride,\n",
    "                               padding=padding, bias=bias)\n",
    "                        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output tensor shape: torch.Size([1, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Define input tensor with shape (batch_size, in_channels, height, width)\n",
    "input_tensor = torch.randn(1, 3, 64, 64)  # Example with batch_size=1, in_channels=3, height=64, width=64\n",
    "\n",
    "# Create an instance of the Conv class\n",
    "conv_layer = Conv(inplanes=3, planes=16, kernel_size=3, stride=1)\n",
    "\n",
    "# Pass the input tensor through the convolutional layer\n",
    "output_tensor = conv_layer(input_tensor)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output tensor shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A convolutional block module combining a convolutional layer, a normalization layer, \n",
    "    and an activation layer.\n",
    "\n",
    "    This class encapsulates a common pattern found in neural networks, where a convolution \n",
    "    is followed by batch normalization and a non-linear activation function. It provides \n",
    "    a convenient way to stack these operations into a single module.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 inplanes: int, # The number of input channels.\n",
    "                 planes: int, # The number of output channels.\n",
    "                 kernel_size: int, # The size of the convolving kernel.\n",
    "                 stride:int=1, # The stride of the convolution.\n",
    "                 conv_layer:nn.Module=nn.Conv2d, # The convolutional layer class to be used.\n",
    "                 norm_layer:nn.Module=nn.BatchNorm2d, # The normalization layer class to be used.\n",
    "                 act_layer:nn.Module=nn.ReLU, # The activation function class to be used.\n",
    "                 **kwargs # Arbitrary keyword arguments. Currently supports 'padding'.\n",
    "                 ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        padding = kwargs.get('padding', kernel_size // 2)  # dafault same size\n",
    "\n",
    "        self.conv = Conv(inplanes, planes, kernel_size=kernel_size, stride=stride,\n",
    "                               padding=padding, bias=False, conv_layer=conv_layer)\n",
    "\n",
    "        self.norm = norm_layer(planes)\n",
    "        self.act = act_layer()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.norm(out)\n",
    "        out = self.act(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1, 16, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Define an instance of the ConvBlock\n",
    "conv_block = ConvBlock(inplanes=3, planes=16, kernel_size=3, stride=1)\n",
    "\n",
    "# Create a dummy input tensor with shape (batch_size, channels, height, width)\n",
    "dummy_input = torch.randn(1, 3, 64, 64)  # Example: batch size of 1, 3 input channels, 64x64 image\n",
    "\n",
    "# Pass the dummy input through the ConvBlock\n",
    "output = conv_block(dummy_input)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic residual block module for neural networks.\n",
    "\n",
    "    This class implements a basic version of the residual block, consisting of two convolutional \n",
    "    blocks followed by an addition operation with the input (identity) and an activation function. \n",
    "    It is a fundamental component in ResNet architectures, allowing for the training of very deep \n",
    "    networks by addressing the vanishing gradient problem.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 inplanes:int, # Number of input channels\n",
    "                 kernel_size:int=3 # Size of the convolving kernel\n",
    "                 ):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.block1 = ConvBlock(inplanes, inplanes, kernel_size=kernel_size)\n",
    "        self.block2 = ConvBlock(inplanes, inplanes, kernel_size=kernel_size)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.block1(x)\n",
    "        out = self.block2(out)\n",
    "        out += identity  # Element-wise addition with the input tensor\n",
    "        out = self.act(out)  # Apply activation function\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicBlock(\n",
      "  (block1): ConvBlock(\n",
      "    (conv): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (block2): ConvBlock(\n",
      "    (conv): Conv(\n",
      "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    )\n",
      "    (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (act): ReLU()\n",
      ")\n",
      "Output shape: torch.Size([1, 64, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Instantiate the BasicBlock\n",
    "basic_block = BasicBlock(64)\n",
    "\n",
    "# Print the structure of the basic_block to understand its components\n",
    "print(basic_block)\n",
    "\n",
    "# Create a random tensor with shape (batch_size, channels, height, width)\n",
    "# Let's assume a batch size of 1, with 64 channels, and spatial dimensions 32x32\n",
    "input_tensor = torch.randn(1, 64, 32, 32)\n",
    "\n",
    "# Pass the input tensor through the BasicBlock\n",
    "output_tensor = basic_block(input_tensor)\n",
    "\n",
    "# Print the shape of the output tensor\n",
    "print(\"Output shape:\", output_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndef replace_feature(out, new_features):\\n    if \"replace_feature\" in out.__dir__():\\n        # spconv 2.x behaviour\\n        return out.replace_feature(new_features)\\n    else:\\n        out.features = new_features\\n        return out\\n'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|export\n",
    "#|hide\n",
    "\"\"\"\n",
    "def replace_feature(out, new_features):\n",
    "    if \"replace_feature\" in out.__dir__():\n",
    "        # spconv 2.x behaviour\n",
    "        return out.replace_feature(new_features)\n",
    "    else:\n",
    "        out.features = new_features\n",
    "        return out\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "#|hide\n",
    "def replace_feature(out, new_features):\n",
    "    if \"replace_feature\" in out.__dir__():\n",
    "        # Use the replace_feature method for SparseConvTensor\n",
    "        return out.replace_feature(new_features)\n",
    "    else:\n",
    "        # Assuming `out` is a SparseConvTensor and it does not have replace_feature method\n",
    "        return spconv.pytorch.SparseConvTensor(new_features, out.indices, out.spatial_shape, out.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class SparseConvBlock(spconv.pytorch.SparseModule):\n",
    "    '''\n",
    "    Initializes a sparse convolutional block for 2D inputs.\n",
    "\n",
    "    This block uses SparseConv2d for strides greater than 1 and SubMConv2d for stride equal to 1.\n",
    "    It includes a normalization and activation layer following the convolution.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int, # Number of channels in the input tensor.\n",
    "                 out_channels: int, # Number of channels produced by the convolution.\n",
    "                 kernel_size: int, # Size of the convolving kernel.\n",
    "                 stride, # Stride of the convolution.\n",
    "                 use_subm:bool=True, # Whether to use SubMConv2d for stride 1.\n",
    "                 bias:bool=False # If True, adds a learnable bias to the output.\n",
    "                 ):\n",
    "        super(SparseConvBlock, self).__init__()\n",
    "        if stride == 1 and use_subm:\n",
    "            self.conv = spconv.pytorch.SubMConv2d(in_channels, out_channels, kernel_size,\n",
    "                                                  padding=kernel_size//2, stride=1, bias=bias,)\n",
    "        else:\n",
    "            self.conv = spconv.pytorch.SparseConv2d(in_channels, out_channels, kernel_size,\n",
    "                                                    padding=kernel_size//2, stride=stride, bias=bias)\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = replace_feature(out, self.norm(out.features))\n",
    "        out = replace_feature(out, self.act(out.features))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvTensor[shape=torch.Size([5, 16])]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Example usage\n",
    "input_tensor = spconv.pytorch.SparseConvTensor(features=torch.randn(5, 3).to(DEVICE),\n",
    "                                               indices=torch.randint(0, 10, (5, 3), dtype=torch.int32).to(DEVICE),\n",
    "                                               spatial_shape=[10, 10],\n",
    "                                               batch_size=1)\n",
    "conv_block = SparseConvBlock(3, 16, 3, 1).to(DEVICE)\n",
    "output_tensor = conv_block(input_tensor)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class SparseBasicBlock(spconv.pytorch.SparseModule):\n",
    "    '''\n",
    "    A basic block for sparse convolutional networks, specifically designed for 2D inputs.\n",
    "\n",
    "    This block consists of two convolutional layers, each followed by normalization and activation.\n",
    "    The output of the second convolutional layer is added to the input feature map (residual connection)\n",
    "    before applying the final activation function.\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 channels:int, # Number of channels in the input tensor.\n",
    "                 kernel_size # Size of the convolving kernel.\n",
    "                 ):\n",
    "        super(SparseBasicBlock, self).__init__()\n",
    "        self.block1 = SparseConvBlock(channels, channels, kernel_size, 1)\n",
    "        self.conv2 = spconv.pytorch.SubMConv2d(channels, channels, kernel_size, padding=kernel_size//2,\n",
    "                                               stride=1, bias=False, algo=ConvAlgo.Native, )\n",
    "        self.norm2 = nn.BatchNorm1d(channels, eps=1e-3, momentum=0.01)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.block1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = replace_feature(out, self.norm2(out.features))\n",
    "        out = replace_feature(out, out.features + identity.features)\n",
    "        out = replace_feature(out, self.act2(out.features))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvTensor[shape=torch.Size([5, 3])]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Example usage\n",
    "input_tensor = spconv.pytorch.SparseConvTensor(features=torch.randn(5, 3).to(DEVICE),\n",
    "                                               indices=torch.randint(0, 10, (5, 3), dtype=torch.int32).to(DEVICE),\n",
    "                                               spatial_shape=[10, 10],\n",
    "                                               batch_size=1)\n",
    "basic_block = SparseBasicBlock(3, 3).to(DEVICE)\n",
    "output_tensor = basic_block(input_tensor)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class SparseConv3dBlock(spconv.pytorch.SparseModule):\n",
    "    '''\n",
    "    Initializes a sparse convolutional block for 3D inputs.\n",
    "\n",
    "    This block uses SparseConv3d for strides greater than 1 and SubMConv3d for stride equal to 1.\n",
    "    It includes a normalization and activation layer following the convolution.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                in_channels: int, # Number of channels in the input tensor.\n",
    "                out_channels: int, # Number of channels produced by the convolution.\n",
    "                kernel_size, # Size of the convolving kernel.\n",
    "                stride, # Stride of the convolution.\n",
    "                use_subm:bool=True # Whether to use SubMConv3d for stride 1.\n",
    "                ):\n",
    "        super(SparseConv3dBlock, self).__init__()\n",
    "        if stride == 1 and use_subm:\n",
    "            self.conv = spconv.pytorch.SubMConv3d(in_channels, out_channels, kernel_size, padding=kernel_size//2,\n",
    "                                                  stride=1, bias=False)\n",
    "        else:\n",
    "            self.conv = spconv.pytorch.SparseConv3d(in_channels, out_channels, kernel_size, padding=kernel_size//2,\n",
    "                                                    stride=stride, bias=False)\n",
    "\n",
    "        self.norm = nn.BatchNorm1d(out_channels, eps=1e-3, momentum=0.01)\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = replace_feature(out, self.norm(out.features))\n",
    "        out = replace_feature(out, self.act(out.features))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvTensor[shape=torch.Size([5, 16])]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Example usage\n",
    "input_tensor = spconv.pytorch.SparseConvTensor(features=torch.randn(5, 3).to(DEVICE),\n",
    "                                               indices=torch.randint(0, 10, (5, 4), dtype=torch.int32).to(DEVICE),\n",
    "                                               spatial_shape=[10, 10, 10],\n",
    "                                               batch_size=1)\n",
    "conv3d_block = SparseConv3dBlock(3, 16, 3, 1).to(DEVICE)\n",
    "output_tensor = conv3d_block(input_tensor)\n",
    "print(output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|exports\n",
    "class SparseBasicBlock3d(spconv.pytorch.SparseModule):\n",
    "    '''\n",
    "    A basic block for sparse convolutional networks, specifically designed for 3D inputs.\n",
    "\n",
    "    This block consists of two convolutional layers, each followed by normalization and activation.\n",
    "    The output of the second convolutional layer is added to the input feature map (residual connection)\n",
    "    before applying the final activation function.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 channels:int, # Number of channels in the input tensor.\n",
    "                 kernel_size # Size of the convolving kernel.\n",
    "                 ):\n",
    "        super(SparseBasicBlock3d, self).__init__()\n",
    "        self.block1 = SparseConv3dBlock(channels, channels, kernel_size, 1)\n",
    "        self.conv2 = spconv.pytorch.SubMConv3d(channels, channels, kernel_size, padding=kernel_size//2,\n",
    "                                               stride=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm1d(channels, eps=1e-3, momentum=0.01)\n",
    "        self.act2 = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        out = self.block1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = replace_feature(out, self.norm2(out.features))\n",
    "        out = replace_feature(out, out.features + identity.features)\n",
    "        out = replace_feature(out, self.act2(out.features))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseConvTensor[shape=torch.Size([5, 3])]\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "# Example usage\n",
    "input_tensor = spconv.pytorch.SparseConvTensor(features=torch.randn(5, 3).to(DEVICE),\n",
    "                                       indices=torch.randint(0, 10, (5, 4), dtype=torch.int32).to(DEVICE),\n",
    "                                       spatial_shape=[10, 10, 10],\n",
    "                                       batch_size=1)\n",
    "basic_block3d = SparseBasicBlock3d(3, 3).to(DEVICE)\n",
    "output_tensor = basic_block3d(input_tensor)\n",
    "print(output_tensor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
